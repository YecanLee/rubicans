from typing import Option, List

import torch
import torch.nn as nn

class AutoEncoder(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class Unet(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class Clip_Model(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class BaSicTransformerBlock(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class CrossAttentionBlock(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class LinearCrossAttentionBlock(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class EfficientAttention(nn.Module):
    pass

class Normal_Attention(nn.Module):
    def __init__(self, q, k, v):
        super().__init__()
        self.q = q
        self.k = k
        self.v = v

class FeedFoward(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class SpatialTransformer(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class TimeStepEmbSequantial(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class Upsample(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass

class Downsample(nn.Module):
    def __init__(self, *args, **kargs):
        super().__init__()

    def forward(self, *args, **kargs):
        pass
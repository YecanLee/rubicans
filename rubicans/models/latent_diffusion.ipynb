{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "from typing import Options, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from stable_diffusion_model import AutoEncoder, Unet, Clip_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class is built to map the pretrained weights with our model\n",
    "class Diffusion_wrapper(nn.Module):\n",
    "    def __init__(self, diffusion_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.diffusion_model = diffusion_model\n",
    "\n",
    "    def forward(self, x: torch.Tensor, T: torch.Tensor, context:torch.Tensor):\n",
    "        result = self.diffusion_model(x, T, context)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDiffusionModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 unet: Unet, \n",
    "                 autoencoder: AutoEncoder, \n",
    "                 clip_emb: Clip_Model, \n",
    "                 latent_scaling_factor: int, \n",
    "                 T:int, \n",
    "                 linear_start: int, \n",
    "                 linear_end: int\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.latent_scaling_facotr = latent_scaling_factor\n",
    "        self.T = T\n",
    "        self.linear_start = linear_start\n",
    "        self.linear_end = linear_end\n",
    "\n",
    "        self.model = Diffusion_wrapper(Unet)\n",
    "        self.first_stage = autoencoder\n",
    "        self.cond_stage_model = clip_emb\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
